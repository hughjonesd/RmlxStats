# RmlxStats

Statistical modelling front-ends that run on Apple GPU hardware via the
[Rmlx](https://github.com/hughjonesd/Rmlx) array library.

## When to use mlxs\_(g)lm

- GPU acceleration shines once the design matrix is large (tens of
  thousands of rows/columns) or you need to refit many times (e.g.,
  bootstraps or cross-validation). In these cases the MLX QR/solve path
  can be several times faster than repeated
  [`lm()`](https://rdrr.io/r/stats/lm.html)/[`glm()`](https://rdrr.io/r/stats/glm.html)
  fits.
- For small problems (think classic textbook data) the overhead of
  launching GPU kernels and shuttling data usually outweighs any
  benefit; base R’s CPU solvers will be faster.
- Residual bootstraps for Gaussian models are particularly effective: we
  reuse the original MLX QR factorisation and only resample residuals,
  so each replicate avoids a fresh factorisation.

## Installation

1.  Install Apple’s MLX runtime (provides the Metal-backed tensor
    engine):

    ``` bash
    brew install mlx
    ```

2.  Install the development dependencies in R (requires R 4.5+ on Apple
    Silicon):

    ``` r
    install.packages(c("devtools", "nycflights13", "bench", "fixest", "RcppEigen", "speedglm"))
    ```

3.  Install Rmlx and RmlxStats from GitHub:

    ``` r
    remotes::install_github("hughjonesd/Rmlx")
    remotes::install_github("hughjonesd/RmlxStats")
    ```

# Package index

## All functions

- [`generics-reexports`](https://hughjonesd.github.io/RmlxStats/reference/generics-reexports.md)
  : Re-export generics
- [`mlxs_binomial()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_binomial.md)
  : MLX-friendly binomial family
- [`mlxs_boot()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_boot.md)
  : Bootstrap MLX arrays along the first dimension
- [`mlxs_gaussian()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_gaussian.md)
  : MLX-friendly Gaussian family
- [`mlxs_glm()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm.md)
  : MLX-backed generalized linear model
- [`coef(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`predict(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`fitted(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`residuals(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`vcov(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`print(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`summary(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`print(`*`<summary.mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`anova(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`model.frame(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`model.matrix(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`terms(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`nobs(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`tidy(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`glance(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  [`augment(`*`<mlxs_glm>`*`)`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glm_methods.md)
  : mlxs_glm method utilities
- [`mlxs_glmnet()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_glmnet.md)
  : MLX-backed elastic net regression
- [`mlxs_lm()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_lm.md)
  : MLX-backed linear regression
- [`mlxs_lm_methods`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_lm_methods.md)
  : mlxs_lm method utilities
- [`mlxs_poisson()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_poisson.md)
  : MLX-friendly Poisson family
- [`mlxs_quasibinomial()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_quasibinomial.md)
  : MLX-friendly quasibinomial family
- [`mlxs_quasipoisson()`](https://hughjonesd.github.io/RmlxStats/reference/mlxs_quasipoisson.md)
  : MLX-friendly quasipoisson family

# Articles

### All vignettes

- [Benchmarks](https://hughjonesd.github.io/RmlxStats/articles/benchmark-lm-mlxs.md):
